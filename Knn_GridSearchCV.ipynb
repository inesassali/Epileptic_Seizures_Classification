{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as k\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Conv1D,Conv2D, MaxPooling1D,Flatten,BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import numpy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "numpy.random.seed(2)"
      ],
      "metadata": {
        "id": "qdOtHNgUCshc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset for electrode 1 (E1)\n",
        "dataset_e1= pd.read_csv(\"/content/drive/MyDrive/Code_IA_Test/E1.csv\",delimiter=\",\")\n",
        "dataset_e1=numpy.array(dataset_e1,float)\n",
        "X_e1 = dataset_e1[:,1:7]\n",
        "# Load dataset for electrode 2 (E2)\n",
        "dataset_e2= pd.read_csv(\"/content/drive/MyDrive/Code_IA_Test/E2.csv\",delimiter=\",\")\n",
        "dataset_e2=numpy.array(dataset_e2,float)\n",
        "X_e2 = dataset_e2[:,1:7]\n",
        "# Extract output (Y)\n",
        "Y= dataset_e1[:,8]\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "QqdEZ3RZaZLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels Histogram\n",
        "Y_histogram = Counter(Y)\n",
        "print(\"Labels Histogram:\", Y_histogram)\n",
        "plt.bar(Y_histogram.keys(), Y_histogram.values(), width=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TkEWiXMEIVnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the proportions of each class\n",
        "interictal_percentage = np.sum(Y == 0) / len(Y)\n",
        "preictal_percentage = np.sum(Y == 1) / len(Y)\n",
        "ictal_percentage = np.sum(Y == 2) / len(Y)\n",
        "\n",
        "# Print the average values of the Y column\n",
        "print('Interictal: {0:.3f} | Preictal: {1:.3f} | Ictal: {2:.3f}'.format(interictal_percentage, preictal_percentage, ictal_percentage))"
      ],
      "metadata": {
        "id": "Q7JAoaN2KZkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Normalize data by dividing each column by the first column of the respective dataset\n",
        "def normalize_data(X, dataset):\n",
        "    lin, col = np.shape(X)\n",
        "    for i in range(col - 2):\n",
        "        X[:, i] = (X[:, i] / dataset[:, 0])\n",
        "\n",
        "# Assuming dataset_e1 and dataset_e2 are defined\n",
        "\n",
        "# Normalize data for X_e1 and X_e2\n",
        "normalize_data(X_e1, dataset_e1)\n",
        "normalize_data(X_e2, dataset_e2)\n",
        "\n",
        "# Step 2: Use StandardScaler for further normalization\n",
        "scaler1 = StandardScaler().fit(X_e1)\n",
        "scaler2 = StandardScaler().fit(X_e2)\n",
        "X_e1 = scaler1.transform(X_e1)\n",
        "X_e2 = scaler2.transform(X_e2)\n",
        "\n",
        "# Step 3: Combine normalized data into a 3D array\n",
        "X = np.stack((X_e1, X_e2), axis=-1)\n",
        "\n",
        "print(\"Shape of X_e1:\", X_e1.shape)\n",
        "print(\"Shape of X_e2:\", X_e2.shape)\n",
        "print(\"Shape of X:\", X.shape)\n",
        "\n",
        "# Step 4: Reshape the 3D array into a 2D array\n",
        "nsamples, nfeatures, nchannels = X.shape\n",
        "X_norm = X.reshape((nsamples, nfeatures * nchannels))\n",
        "\n",
        "print(\"Shape of X_norm:\", X_norm.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "RhSBmF9XzU6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into 80% training and 20% (testing and validating)\n",
        "# Step 1: Split into 80% training and 20% (testing + validating)\n",
        "X_train, X_val_test, Y_train, Y_val_test = train_test_split(X_norm, Y, test_size=0.2)\n",
        "\n",
        "# Step 2: Further split the 20% into 10% validation and 10% testing\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_val_test, Y_val_test, test_size=0.5)\n",
        "\n",
        "# Print shapes of the resulting datasets\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of Y_train:\", Y_train.shape)\n",
        "print(\"Shape of X_val:\", X_val.shape)\n",
        "print(\"Shape of Y_val:\", Y_val.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of Y_test:\", Y_test.shape)\n"
      ],
      "metadata": {
        "id": "Q3kdZ31uzcfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a KNN model\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
        "grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, Y_train)\n",
        "\n",
        "# Get the best parameters from the grid search\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train the KNN model with the best hyperparameters\n",
        "best_knn_model = KNeighborsClassifier(n_neighbors=best_params['n_neighbors'], weights=best_params['weights'])\n",
        "best_knn_model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "QZd4nwOjzmAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "knn_predictions = best_knn_model.predict(X_test)\n",
        "\n",
        "# Calculate various metrics\n",
        "accuracy_knn = accuracy_score(knn_predictions, Y_test)\n",
        "precision_knn = precision_score(knn_predictions, Y_test, average='macro')\n",
        "recall_knn = recall_score(knn_predictions, Y_test, average='macro')\n",
        "f1_knn = f1_score(knn_predictions, Y_test, average='macro')\n",
        "\n",
        "# Print metric scores for the KNN model\n",
        "print(\"\\nMetric scores for KNN:\")\n",
        "print(\" Accuracy: {:.2f} %\".format(accuracy_knn * 100))\n",
        "print(\" Precision: {:.2f} %\".format(precision_knn * 100))\n",
        "print(\" Recall: {:.2f} %\".format(recall_knn * 100))\n",
        "print(\" F1: {:.2f} %\".format(f1_knn * 100))\n",
        "\n",
        "# Generate and print a detailed classification report for the KNN model\n",
        "clf_report_knn = classification_report(Y_test, knn_predictions)\n",
        "print(\"\\nClassification Report for KNN:\")\n",
        "print(clf_report_knn)\n",
        "\n",
        "# Display the confusion matrix\n",
        "cm = confusion_matrix(Y_test, knn_predictions)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1', '2'], yticklabels=['0', '1', '2'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rumjnjZnMq-o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}