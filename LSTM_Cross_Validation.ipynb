{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uNK_K9QW3P1u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, Activation, BatchNormalization, GRU, LSTM\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset for electrode 1 (E1)\n",
        "dataset_e1= pd.read_csv(\"/content/drive/MyDrive/Code_IA_Test/E1.csv\",delimiter=\",\")\n",
        "dataset_e1=np.array(dataset_e1,float)\n",
        "X_e1 = dataset_e1[:,1:6]\n",
        "# Load dataset for electrode 2 (E2)\n",
        "dataset_e2= pd.read_csv(\"/content/drive/MyDrive/Code_IA_Test/E2.csv\",delimiter=\",\")\n",
        "dataset_e2=np.array(dataset_e2,float)\n",
        "X_e2 = dataset_e2[:,1:6]\n",
        "# Extract output (Y)\n",
        "Y= dataset_e1[:,8]\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "s2vdlrpm32-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data\n",
        "# Step1\n",
        "lin,col =np.shape(X_e1)\n",
        "for i in range(0, col-2):\n",
        "    X_e1[:, i] = (X_e1[:, i]/dataset_e1[:, 0])\n",
        "    X_e2[:, i] = (X_e2[:, i]/dataset_e2[:, 0])\n",
        "\n",
        "# Step 2: Use StandardScaler for further normalization\n",
        "scaler1 = StandardScaler().fit(X_e1)\n",
        "scaler2 = StandardScaler().fit(X_e2)\n",
        "X_e1 = scaler1.transform(X_e1)\n",
        "X_e2 = scaler1.transform(X_e2)\n",
        "\n",
        "# Step 3: Combine normalized data into a 3D array\n",
        "X=np.zeros((X_e1.shape[0],X_e1.shape[1],2))\n",
        "X[:,:,0]=X_e1\n",
        "X[:,:,1]=X_e2\n",
        "\n",
        "print(\"Shape of X_e1:\", X_e1.shape)\n",
        "print(\"Shape of X_e2:\", X_e2.shape)\n",
        "print(\"Shape of X:\",X.shape)"
      ],
      "metadata": {
        "id": "bgOZlafQ5CDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "x_train_new=x_train.copy()\n",
        "x_test_new = x_test.copy()\n",
        "# Convert labels to categorical\n",
        "Y_train_new = tf.keras.utils.to_categorical(y_train)\n",
        "Y_test_new = tf.keras.utils.to_categorical(y_test)\n",
        "print(\"Shape of y_train:\",y_train.shape)\n",
        "print(\"Shape of Y_train_new:\", Y_train_new.shape)"
      ],
      "metadata": {
        "id": "EjBkiQ2m5KG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add LSTM layers\n",
        "model.add(LSTM(128, return_sequences=True, input_shape=(5, 2), activation='relu'))\n",
        "model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
        "model.add(LSTM(32, return_sequences=True, activation='relu'))\n",
        "model.add(LSTM(32, return_sequences=True, activation='relu'))\n",
        "model.add(LSTM(16))\n",
        "\n",
        "# Add Dense and Activation layers\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,\n",
        "                                        beta_1=0.9,\n",
        "                                        beta_2=0.999,\n",
        "                                        epsilon=1e-07,\n",
        "                                        amsgrad=False,\n",
        "                                        name='Adam'),\n",
        "              metrics=['accuracy'])\n",
        ""
      ],
      "metadata": {
        "id": "FkOsoq_66waD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply cross-validation using 3 folds\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "for train_index, val_index in kf.split(x_train_new):\n",
        "    # Split the data into training and validation sets\n",
        "    x_train, x_val = x_train_new[train_index], x_train_new[val_index]\n",
        "    Y_train, y_val = Y_train_new[train_index], Y_train_new[val_index]\n",
        "\n",
        "    # Further split the training set into training and testing sets\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, Y_train, test_size=0.15, random_state=42)\n",
        "\n",
        "    # Reshape the data to fit the model\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 2))\n",
        "    x_val= np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 2))\n",
        "\n",
        "    # Train the model on the current training data\n",
        "    checkpointer = ModelCheckpoint(filepath='./'+'_best_weights.h5', verbose=1, monitor='val_loss', mode='auto', save_best_only=True)\n",
        "\n",
        "    # Save the best weights based on validation loss\n",
        "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=32, callbacks=[checkpointer])"
      ],
      "metadata": {
        "id": "Hsf9Rzfs68Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "score = model.evaluate(x_test_new, Y_test_new, verbose=1)\n",
        "\n",
        "# Display the test loss and accuracy\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "2HD3p1tJ9nuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mw23210K9yQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend( loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dU7AlLGb-o5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test_new, batch_size=128, verbose=2)\n",
        "print (\"Predicted data shape:\", predictions.shape)\n",
        "print(\"True labels shape:\", Y_test_new.shape)"
      ],
      "metadata": {
        "id": "B7l8atdb-06l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the custom threshold for positive predictions\n",
        "threshold_confusion = 0.5\n",
        "print (\"\\nConfusion matrix:  Custom threshold (for positive) of \" +str(threshold_confusion))\n",
        "\n",
        "# Initialize arrays to store predicted and true labels\n",
        "y_pred = np.empty((predictions.shape[0]))\n",
        "y_test = np.empty((predictions.shape[0]))\n",
        "\n",
        "# Populate the arrays with predicted and true labels\n",
        "for i in range(predictions.shape[0]):\n",
        "    y_pred[i]=np.argmax(predictions[i])\n",
        "    y_test[i]=np.argmax(Y_test_new[i])\n",
        "\n",
        "# Calculate and display the confusion matrix\n",
        "confusion = confusion_matrix(y_test,  y_pred)\n",
        "print (confusion)"
      ],
      "metadata": {
        "id": "adVnf5AkAQ4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"The accuracy score on this random test-set is:\", accuracy)\n",
        "\n",
        "# Calculate and display recall\n",
        "recall = recall_score(y_test, y_pred, average=None)\n",
        "average_recall = sum(recall) / len(recall)\n",
        "print(\"Recall:\", recall, \"The average recall is\", average_recall)\n",
        "\n",
        "# Calculate and display precision\n",
        "precision = precision_score(y_test, y_pred, average=None)\n",
        "average_precision = sum(precision) / len(precision)\n",
        "print(\"Precision:\", precision, \"The average precision is\", average_precision)\n",
        "\n",
        "# Calculate and display F1 score\n",
        "f1_score = (2 * average_precision * average_recall) / (average_precision + average_recall)\n",
        "print(\"F1 Score:\", f1_score)"
      ],
      "metadata": {
        "id": "PzSoYY48AphO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}